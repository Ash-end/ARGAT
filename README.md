# ARGAT.py
Automatic Modulation Recognition of Radio  Frequency Proximity Sensor Signals Based on  Adaptive Relational Graph Attention Network

​	This project utilizes the Adaptive Relational Graph Attention Network (ARGAT) for Automatic Modulation Recognition (AMR) of Radio Frequency Proximity Sensor (RFPS) signals. The project is built on the PyTorch framework, which is specifically designed to handle large-scale datasets. The ARGAT model consists of several key components: the G layer, the GAT layer, the T layer, and three fully connected layers. This model combines traditional graph convolution operations with a graph attention mechanism to capture the complex relationships within graph-structured data. Readers are encouraged to experiment with these layers to construct their own models, though it is important to ensure that the dimensions between layers match, which often requires dimension transformations.

​	Training and Validation: The model is trained on the training data using CrossEntropyLoss and the AdamW optimizer. Additionally, a ReduceLROnPlateau learning rate scheduler is used to dynamically adjust the learning rate, and early stopping is implemented to prevent overfitting. Testing and Evaluation: Upon completion of training, the best model is loaded and evaluated on the test set, calculating and reporting the loss and accuracy. Additionally, loss and accuracy curves are plotted during training and validation, and a confusion matrix is generated to assess the classification performance.

​	All critical parameter matches are indicated in the code. Additionally, readers are encouraged to modify these parameters to create their own models. The model is configured with 40 graph nodes and 512 data points per node. Readers can modify the number of nodes and data points to suit their own signal data.

​	The adjacency matrix of the graph can be computed by referring to the `ASCC.py` file.

​	Finally, it is essential to ensure that the dimensionality matching between layers is properly carried out.

# ASCC.py

​	The script [ASCC.py](http://ascc.py/) represents the code implementation of the ASCC mathematical model and is utilized to process data to obtain a normalized adjacency matrix. The specific operational procedure is as follows:
​	Calculate FFT correlation: Use fast Fourier transform (FFT) to calculate the normalized mutual correlation coefficient of two signals and evaluate their similarity. PCA dimensionality reduction: Use principal component analysis (PCA) method to reduce the dimension of the signal set, reduce the feature dimension, and retain the variance of the data as much as possible. Calculate Pearson correlation coefficient matrix: Calculate the Pearson correlation coefficient matrix on the reduced signal set to evaluate the linear relationship between different signals. Construct adjacency matrix: Combine FFT normalized mutual correlation and Pearson correlation coefficient to construct the adjacency matrix of the graph. Calculate degree matrix: Calculate the degree matrix of the graph based on the adjacency matrix for subsequent regularization processing. Regularize adjacency matrix: Use the degree matrix to calculate the normalized adjacency matrix for use in graph algorithms. Data processing and storage: After processing, the labels, signals and corresponding adjacency matrices are merged and saved in a new data file for subsequent analysis and model training.

​	The key parameters that require attention are clearly annotated within the code. Notably, certain parameters—such as the number of nodes and the dimensionality of node signals—must correspond with those specified in [ARGAT.py](http://argat.py/), as well as in `LoadTrainData`  ,`LoadTestData`，,`LoadvaliData`， and `DataGenerator` (We strongly encourage readers to implement these three functions independently, as doing so will provide a complete understanding of the model.) . 

​	Besides, to achieve optimal training results, readers are encouraged to experiment with hyperparameters, such as learning rate, weight decay, and model parameters. Additionally, modifications to the activation functions within the model can also be explored. Thank you for your attention.
